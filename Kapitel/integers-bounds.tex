\section{Abschätzung von Abständen optimaler Lösungen}

Um eine simple Abschätzung, die zusätzlich von der Dimension $n$ abhängt, herzuleiten, wird das folgende Theorem genutzt, das von Cook et al. in~\cite[Theorem 1 und Bemerkung 1]{Cook1986} formuliert wurde:

\begin{theorem}[Cook et al., 1986]\label{thm:cook}
	Seien $I, J\subseteq\firstNumbers{n}$, sodass ($J$-\MIPR) eine optimale Lösung hat und entweder $I=\emptyset$ oder $J=\emptyset$ gilt.
	Dann existiert für jede optimale Lösung $x^*$ von ($I$-\MIPR) eine optimale Lösung $y^*$ von ($J$-\MIPR) mit $\norm{x^*-y^*}\leq n\Delta$.
\end{theorem}

Mit Hilfe dieses Theorems kann nun für allgemeine Indexmengen eine ähnliche obere Grenze gefunden werden:
\begin{corollary}
	Seien $I,J\subseteq\firstNumbers{n}$, sodass ($J$-\MIPR) eine optimale Lösung
	hat.
	Dann existiert für jede optimale Lösung $x^*$ von ($I$-\MIPR) eine optimale Lösung $y^*$ von ($J$-\MIPR) mit $\norm{x^*-y^*}\leq2 n\Delta$.
\end{corollary}
\begin{proof}
	Sei $x^*$ optimale Lösung von ($I$-\MIPR).
	Nach dem Korollar aus dem Theorem von Meyer in~\cite[Korollar 5.2]{Meyer1974} (siehe auch Bemerkung~\ref{rem:feasibility}) existiert eine optimale Lösung für ($\emptyset$-\MIPR).
	
	Daher folgt nach Theorem~\ref{thm:cook} die Existenz einer optimalen Lösung $z^*$ von ($\emptyset$-\MIPR) mit $\norm{x^*-z^*}\leq n\Delta$.
	Wendet man das Theorem ein weiteres Mal folgt die Existenz einer optimalen Lösung $y^*$ von \mbox{($J$-\MIPR)} mit $\norm{z^*-y^*}\leq n\Delta$.
	Mit Hilfe der Dreiecksungleichung gelangt man zur Abschätzung $\norm{x^*-y^*}\leq\norm{x^*-z^*}+\norm{z^*-y^*}\leq 2 n\Delta$.
\end{proof}

In diesem Abschnitt wird diese Aussage nun verstärkt, indem in der Abschätzung $2 n$ durch $\betrag{I\cup J}$ ersetzt wird, also durch die Anzahl der Variablen, die in ($I$-\MIPR) oder \mbox{($J$-\MIPR)} ganzzahlig sind.

\subsection{Folgerungen aus Davenport-Konstante von $p$-Gruppen}

Spannenderweise lässt sich aus der Theorie endlicher Gruppen nun ein wichtiges Hilfslemma für unser Problem mit Hilfe der sogenannten Davenport-Konstante herleiten:

\begin{definition}[Davenport-Konstante]
	Sei $(G,+,0)$ eine endliche, abelsche Gruppe.
	Die {\em Davenport-Konstante} von $G$ ist
	$$
		D(G):=\min\{k\in\N \mid \forall g^1,\dots,g^k \in G~\exists I\subseteq\firstNumbers{k}\colon I\neq\emptyset \wedge \sum_{i\in I}g^i=0  \} .
	$$
\end{definition}

Olson hat in~\cite{Olson1969} die Davenport-Konstante für sogenannte $p$-Gruppen ermittelt.
Für die Interpretation seiner Aussage ist der Begriff der invarianten Faktoren einer endlichen abelschen Gruppe nötig.
Dieser wird im Hauptsatz endlicher abelscher Gruppen, der beispielsweise in~\cite[Satz 10.6]{Karpfinger2017} zu finden ist, eingeführt.

\begin{definition}[$p$-Gruppe]
	Sei $p$ eine Primzahl.
	Eine \emph{$p$-Gruppe} ist eine Gruppe, in der die Ordnung jedes Elements eine Potenz von $p$ ist.
\end{definition}
\begin{theorem}[Hauptsatz endlicher abelscher Gruppen]
	Sei $G$ eine endliche abelsche Gruppe.
	$C_n$ bezeichne die zyklische Gruppe mit Ordnung $n$.
	Dann existiert eine eindeutige Darstellung $G\cong C_{n_1}\times\cdots\times C_{n_d}$ mit $2\leq n_1\mid\cdots\mid n_d$.
	Die Zahlen $n_1,\dots,n_d$ werden dabei als die sogenannten \emph{invarianten Faktoren von $G$} bezeichnet.
\end{theorem}

Auf dieser Grundlage basiert nun die folgende Aussage von Olson:

\begin{theorem}[Olson, 1969]\label{thm:olson}
	Für eine endliche abelsche $p$-Gruppe $G$ mit invarianten Faktoren $p^{e_1},\dots,p^{e_r}$ ist die Davenport-Konstante $D(G)=1+\sum_{i=1}^r(p^{e_i}-1)$.
\end{theorem}

Mit diesem Ergebnis kann leicht eine hier relevante Folgerung beschreiben:

\begin{corollary}\label{cor:olson}
	Seien $p\in\N$ eine Primzahl, $d\in\N$ und $f^1,\dots,f^r\in\Z^d$ mit $r\geq 1+dp-d$.
	Dann existiert eine nicht-leere Menge $I\subseteq\firstNumbers{r}$ mit $\sum_{i\in I}f^i\in p\Z^d$.
\end{corollary}
\begin{proof}
	Die $d$ invarianten Faktoren der $p$-Gruppe $\Z^d/p\Z^d\cong C_p\times\dots\times C_p$ sind jeweils $p$ und mit Theorem~\ref{thm:olson} ist $D(\Z^d/p\Z^d)=1+\sum_{i=1}^d(p-1)=1+dp-d$.
	
	Nach Definition der Davenport-Konstante existiert eine nichtleere Menge $I\subseteq\firstNumbers{1+dp-d}$ mit $\sum_{i\in I}[f^i]_p=[0]_p=p\Z^d$.
	Mit $\firstNumbers{1+dp-d}\subseteq\firstNumbers{r}$ und $\sum_{i\in I}[f^i]_p=[\sum_{i\in I}f^i]_p$ folgt die Behauptung.
\end{proof}

Damit kann das folgende Lemma gezeigt werden, das in~\cite{Paat2018} als Lemma~1 bezeichnet wird.

\begin{lemma}\label{lem:olson}
	Seien $d,k\in\N, u^1,\dots, u^k\in\Z^d$ und $\alpha_1,\dots,\alpha_k\geq0$ mit $\sum_{i=1}^k \alpha_i\geq d$.
	Dann existiert $\beta\in\bigtimes_{i=1}^k[0,\alpha_i]$ mit $\beta\neq0$ und $\sum_{i=1}^k\beta_i u^i \in\Z^d$.
\end{lemma}
\begin{proof}
	\newcommand{\bbeta}{\tilde{\beta}}
	Ohne Beschränkung der Allgemeinheit sei $\alpha_i>0$ für $i=1,\dots,k$, denn für $\alpha_i=0$ wird $\beta_i=0$ vorausgesetzt, wodurch das Resultat nicht verändert werden kann.
	
	Zunächst betrachte man den Fall der Existenz einer Primzahl $p$, die $\alpha_i=q_i / p$ mit bestimmten $q_i\in\N$ für alle $i\in\firstNumbers{k}$ erfüllt.
	Wir können nun Korollar~\ref{cor:olson} auf die Vektoren
	$$\underbrace{u^1,\dots,u^1}_{q_1~\text{Einträge}},~\dots~,\underbrace{u^k,\dots,u^k}_{q_k~\text{Einträge}}$$
	anwenden, da nach Voraussetzung $r:=\sum_{i=1}^k q_i=(\sum_{i=1}^k \alpha_i)\cdot p\geq dp \geq 1+dp-d$ gilt.
	Dadurch erhält man $l_i\in\{0,\dots,q_i\}$ für $i\in\firstNumbers{k}$ mit nicht alle $l_i=0$ und $\sum_{i=1}^k l_i u^i\in p\Z^d$.
	Teilt man durch $p$ gelangt man mit $\beta_i := l_i/p$ zur Behauptung $\sum_{i=1}^k \beta_i u^i\in\Z^d$ und $\beta\neq0$ sowie $\beta_i\in[0,\alpha]$, da $0\leq l_i/p\leq q_i/p=\alpha_i$.
	
	Der allgemeine Fall wird auf den Spezialfall zurückgeführt, indem $(\alpha_1,\dots,\alpha_k)\in\R^k$ durch Brüche mit Primzahlen im Nenner angenähert wird.
	Dazu definiere man die Folge 
	$$
	(v^j)_{j\in\N}:=(q^j_1/p^j,\dots,q^j_k/p^j)_{j\in\N}$$
	mit $q^j_i\in\N$, $p^j$ Primzahl und $q^j_i/p^j\in[\alpha_i, \alpha_i+j^{-1}]$.
	Damit ist $\lim_{j\rightarrow\infty}v^j=(\alpha_1,\dots,\alpha_k)$ und für $j\in\N$ kann der Spezialfall auf $u$ und $v^j$ angewandt werden, wodurch man Vorfaktoren $\beta^j\in\bigtimes_{i=1}^k[0,v^j_i]$ mit $\beta^j\neq0$ sowie $\sum_{i=1}^k\beta^j_i u^i \in\Z^d$ erhält.
	Da die Folge $(\beta^j)_{j\in\N}$ in der kompakten Menge $\bigtimes_{i=1}^k[0,\alpha_i+1]$ liegt, existiert nach Satz von Bolzano-Weierstraß eine konvergente Teilfolge mit $\lim_{j\to\infty} \beta^{\sigma(j)}=:\beta$.
	Aus $\beta^{\sigma(j)}_i\in[0,v^{\sigma(j)}_i]$ und $\lim_{j\to\infty}v^{\sigma(j)}_i=\alpha_i$ folgt nun $\beta_i\in[0,\alpha_i]$.
	Da es nur endlich viele $z\in\Z^d$ der Form $z=\sum_{i=1}^k\gamma_i u^i$ mit $\gamma_i\in[0,\alpha_i+1]$ gibt, existiert ein Punkt $z\in\Z^d$, für den $\sum_{i=1}^k \beta^{\sigma(j)}_i u^i=z$ für unendlich viele $j$ gilt.
	Also gibt es wegen der Konvergenz von $(\beta^{\sigma(j)})_{j\in\N}$ ein $n$, sodass $\sum_{i=1}^k\beta^{\sigma(j)}_i u^i=z$ für alle $j\geq n$ gilt, und damit ist $\sum_{i=1}^k\beta_i u^i=z$.
	
	Ist $\beta\neq0$, so erfüllt es die Behauptung.
	Andernfalls ist $z=0$.
	Setze $\varepsilon>0$ so klein, dass $\varepsilon\beta^{\sigma(n)}_i\in[0,\alpha_i]$ für $i\in\firstNumbers{k}$.
	Nach Wahl von $\beta^{\sigma(n)}$ ist dann $\varepsilon\beta^{\sigma(n)}\neq0$ und es gilt $$\sum_{i=1}^k\varepsilon\beta^{\sigma(n)}_iu^i=\varepsilon z=\zero\in\Z^d.$$
\end{proof}

Im nächsten Schritt wird das Resultat dieses Unterkapitels formuliert, welches in der Abschätzung im nächsten Unterkapitel benötigt wird.

\begin{lemma}\label{lem:maxgamma}
	Seien $d\in\N$, $u^i\in\Z^d$ sowie $\lambda_i\geq0$ für $i\in\firstNumbers{k}$ gegeben.
	Dann existiert $\gamma\in\bigtimes_{i=1}^k [0,\lambda_i]$ mit $\sum_{i=1}^k \gamma_i u^i\in\Z^d$ und  $\sum_{i=1}^k(\lambda_i-\gamma_i)<d$.
\end{lemma}
\begin{proof}
	Die beschränkte Menge $G:=\{\gamma \in \bigtimes_{i=1}^k [0,\lambda_i] \mid \sum_{i=1}^k \gamma_i u^i\in\Z^d \}$ ist abgeschlossen: Sei $(\gamma^n)_{n\in\N}$ eine in $\R^k$ konvergente Folge mit $\gamma^n\in G$ für $n\in\N$ und $\lim_{n\to\infty}\gamma^n=:\tilde{\gamma}$.
	Da es nur endlich viele $z\in\Z^d$ mit $z=\sum_{i=1}^k\gamma_iu^i$ für $\gamma_i\in[0,\lambda_i]$ gibt, existiert ein $z\in\Z^d$, sodass $z=\sum_{i=1}^k\gamma^n_iu^i$ für unendlich viele $\gamma^n$ gilt und damit auch für $\tilde{\gamma}\in G$.
	Also ist $G$ abgeschlossen und mit dem Satz von Heine-Borel auch kompakt.
	Nach dem Satz von Weierstraß nimmt $\gamma \mapsto \sum_{i=1}^k\gamma_i$ also bei einem $\gamma$ ihr Maximum auf $G$ an.
	
	Angenommen, es gelte $\sum_{i=1}^k(\lambda_i - \gamma_i) \geq d$.
	Wird Lemma~\ref{lem:olson} auf $\alpha_i:=\lambda_i-\gamma_i\geq0$ und $u^i$ für $i\in\firstNumbers{k}$ angewandt, folgt die Existenz von $\beta\in\bigtimes_{i=1}^k[0,\lambda_i-\gamma_i]$ mit $\beta\neq0$ und $\sum_{i=1}^k \beta_i u^i\in\Z^d$.
	Für $\gamma':=\gamma+\beta\leq\lambda$ gilt 
	$
	\sum_{i=1}^k\gamma'_iu^i = \sum_{i=1}^k\gamma_iu^i + \sum_{i=1}^k \beta_iu^i\in\Z^d
	$
	und damit ist auch $\gamma'\in G$.
	Wegen $\beta\neq0$ ist $\sum_{i=1}^k\gamma'_i > \sum_{i=1}^k\gamma_i$, was im Widerspruch zur Maximalität von $\gamma$ steht.
\end{proof}

\subsection{Abschätzung anhand Anzahl ganzzahliger Variablen}
Dieser Abschnitt verfolgt nun das Ziel eine Abschätzung optimaler Lösungen zweier gemischt-ganzzahliger Programme	($I$-\MIPR) und ($J$-\MIPR) in Abhängigkeit von $\Delta$ und $\betrag{I\cup J}$ zu finden.

Zunächst wird folgendes Hilfslemma über die Darstellung eines polyedrischen Kegels betrachtet.
Dieses ist als Standardresult in der Theorie ganzzahliger Optimierung bekannt und wird beispielsweise in~\cite[Lemma 5.4]{Korte2012} bewiesen.
\begin{lemma}\label{lem:cone}
	Sei $A\in\Z^{m\times n}$, dessen Zeilen in zwei Untermatrizen $A_1$ und $A_2$ aufgeteilt sind.
	Die Menge $C:=\{ x\in\R^n \mid A_1x\leq 0, A_2x\geq0 \}$ besitzt die Darstellung \[ C=\{\lambda_1 v^1+\dots+\lambda_kv^k \mid \forall i\in\firstNumbers{k} \colon\lambda_i\geq0 \}\] mit $v^i\in\Z^n$ und $\norm{v^i}\leq\Delta(A)$ für $i\in\firstNumbers{k}$.
\end{lemma}

Nun wird das Theorem zur Abschätzung anhand der Anzahl ganzzahliger Variablen bewiesen:

\begin{theorem}\label{thm:theo2}
	Seien $I,J\subseteq\firstNumbers{n}$, sodass ($J$-\MIPR) eine optimale Lösung $\tilde{y}$ hat.
	Für jede optimale Lösung $x^*$ von ($I$-\MIPR) existiert eine optimale Lösung $y^*$ von ($J$-\MIPR) mit $\norm{x^*-y^*}\leq\betrag{I\cup J}\cdot\Delta$.
\end{theorem}
\begin{proof}
	Ohne Einschränkung seien $I$ und $J$ nicht beide leer.
	Zunächst werden alle ganzzahligen Variablen an die ersten Stellen getauscht und es kann $I\cup J=\firstNumbers{d}$ mit $d\in\firstNumbers{n}$ angenommen werden.
	Es sei eine optimale Lösung $x^*$ von ($I$-\MIPR) gegeben.
	Setze $C:=\{ x\in\R^n \mid A_1 x \leq 0, A_2x\geq0 \}$, wobei die Zeilen von $A$ in $A_1$ und $A_2$ so aufgeteilt werden, dass $A_1 (\tilde{y}-x^*)<0$ und $A_2 (\tilde{y}-x^*)\geq0$ erfüllt werden.
	Nach Lemma~\ref{lem:cone} erhält man die Darstellung 
	$$\tilde{y}-x^* = \lambda_1v^1 + \dots+\lambda_kv^k$$
	mit $\lambda_i\geq0$, $\norm{v^i}\leq \Delta$ und $v^i\in C\cap\Z^n$ für alle $i\in\firstNumbers{k}$.
	Man setze $u^i$ als die Projektion des Vektors $v^i$ auf dessen erste $d$ Komponenten.
	Nach Lemma~\ref{lem:maxgamma} existiert ein $\gamma\in\bigtimes_{i=1}^k[0,\lambda_i]$ mit  $\sum_{i=1}^k\gamma_iu^i\in\Z^d$ und $\sum_{i=1}^k(\lambda_i -\gamma_i)<d$.
	
	Wir definieren nun unseren Kandidaten $$y^*:=\tilde{y}-\sum_{i=1}^k\gamma_iv^i=x^*+\sum_{i=1}^k(\lambda_i-\gamma_i)v^i$$
	sowie $$\tilde{x}:=x^*+\sum_{i=1}^k\gamma_iv^i=\tilde{y}-\sum_{i=1}^k(\lambda_i-\gamma_i)v^i.$$
	Zunächst zeigen wir, dass $y^*$ für ($J$-\MIPR) und $\tilde{x}$ für ($I$-\MIPR) zulässig sind.
	Dabei sind für $i\in I$ und $j\in J$ die Koordinaten $\tilde{x}_i$ und $y^*_j$ ganzzahlig, weil bereits $x^*_i$ und $\tilde{y}_j$ für $i,j\in\firstNumbers{d}$ ganzzahlig sind und $\sum_{i=1}^k\gamma_iv^i\in\Z^d\times\R^{n-d}$ gilt.
	Die Ungleichungen $Ay^*\leq b$ und $A\tilde{x}\leq b$ folgen nun mit $v^i\in C$ für alle $i\in\firstNumbers{k}$ und 
	$$
	\begin{array}{lllllll}
	A_1 y^*&=&A_1x^*+\sum_{i=1}^k(\lambda_i-\gamma_i)A_1v^i &\leq& A_1 x^* &\leq&b_1\\
	A_2 y^*&=&A_2\tilde{y}-\sum_{i=1}^k\gamma_iA_2v^i &\leq& A_2\tilde{y} &\leq& b_2\\
	A_1\tilde{x} &=&A_1x^*+\sum_{i=1}^k \gamma_iA_1v^i &\leq& A_1x^* &\leq&b_1\\
	A_2\tilde{x} &=&A_2\tilde{y}-\sum_{i=1}^k(\lambda_i-\gamma_i)A_2v^i&\leq& A_2\tilde{y}&\leq& b_2.
	\end{array}
	$$
	
	Da $x^*$ optimal für ($I$-\MIPR) ist, gilt $c\transpose x^*\geq c\transpose \tilde{x} = c\transpose x^* + c\transpose (\sum_{i=1}^k\gamma_iv^i)$.
	Zieht man auf beiden Seiten $c\transpose x^*$ ab, folgt $c\transpose(\sum_{i=1}^k\gamma_iv^i)\leq0$.
	Damit folgert man mit der Optimalität von $\tilde{y}$ für ($J$-\MIPR) und mit 
	$c\transpose y^*=c\transpose\tilde{y}-c\transpose(\sum_{i=1}^k\gamma_iv^i)\geq c\transpose\tilde{y}$
	auch die Optimalität von $y^*$ für ($J$-\MIPR).
	Es gelten die folgenden Abschätzungen:
	$$\norm{x^*-y^*}=\norm{\sum_{i=1}^k(\lambda_i-\gamma_i)v^i}\leq \sum_{i=1}^k(\lambda_i-\gamma_i)\norm{v^i}\leq \sum_{i=1}^k(\lambda_i-\gamma_i)\Delta\leq d\Delta.
	$$
\end{proof}
\begin{remark}
	In der letzten Zeile des Beweises kann man erkennen, dass für $A\neq 0$ und $I$,$J$ nicht beide leer sogar die strikte Abschätzung $\norm{x^*-y^*}<\betrag{I\cup J}\cdot\Delta$ gilt, da dann $\Delta$ ungleich $0$ ist.
\end{remark}
