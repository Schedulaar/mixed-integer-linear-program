
\section{Abschätzungen in Abhängigkeit von $\Delta$}

Um eine Abschätzung, die zusätzlich von der Dimension $n$ abhängt, leicht herzuleiten, nutzen wir das folgende Theorem, das von Cook u. a. in~\cite[Theorem 1 und Bemerkung 1]{Cook1986} formuliert wurde:

\begin{theorem}[Cook u. a., 1986]\label{thm:cook}
	Seien $I, J\subseteq\firstNumbers{n}$, sodass ($J$-\MIP) eine optimale Lösung hat und entweder $I=\emptyset$ oder $J=\emptyset$.
	Dann existiert für jede optimale Lösung $x^*$ von ($I$-\MIP) eine optimale Lösung $y^*$ von ($J$-\MIP) mit $\norm{x^*-y^*}\leq n\cdot\Delta$.
\end{theorem}

Mit Hilfe dieses Theorems können wir nun eine ähnliche obere Grenze finden:
\begin{corollary}
	Seien $I,J\subseteq\firstNumbers{n}$, sodass ($J$-\MIP) eine optimale Lösung
	hat. Dann existiert für jede optimale Lösung $x^*$ von ($I$-\MIP) eine optimale Lösung $y^*$ von ($J$-\MIP) mit $\norm{x^*-y^*}\leq2\cdot n\cdot\Delta$.
\end{corollary}
\begin{proof}
	Sei $x^*$ optimale Lösung von ($I$-\MIP).
	Nach Theorem~\ref{thm:cook} existiert eine optimale Lösung $z^*$ von ($\emptyset$-\MIP) mit $\norm{x^*-z^*}\leq n\cdot\Delta$ und eine optimale Lösung $y^*$ von ($J$-\MIP) mit $\norm{z^*-y^*}\leq n\cdot\Delta$.
	Nach Dreiecksungleichung ist $\norm{x^*-y^*}\leq\norm{x^*-z^*}+\norm{z^*-y^*}\leq 2\cdot n\cdot\Delta$.
\end{proof}

In diesem Abschnitt wollen wir nun diese Aussage verstärken, indem wir in der Abschätzung $2\cdot n$ durch $\betrag{I\cup J}$, also der Anzahl der Variablen, die in ($I$-\MIP) oder ($J$-\MIP) ganzzahlig sind.

\subsection{Folgerungen aus Davenport-Konstante von $p$-Gruppen}

Ein wichtiges Hilfslemma dafür lässt sich aus der sogenannten Davenport-Konstante herleiten:

\begin{definition}[Davenport-Konstante]
	Sei $(G,+,0)$ eine endliche, abelsche Gruppe. Die {\em Davenport-Konstante} von $G$ ist
	$$
		D(G):=\min\{k\in\N \mid \forall g^1,\dots,g^k \in G~\exists I\subseteq\firstNumbers{k}\colon I\neq\emptyset \wedge \sum_{i\in I}g^i=0  \} .
	$$
\end{definition}

Olson hat in~\cite{Olson1969} die Davenport-Konstante für sogenannte $p$-Gruppen ermittelt:
\begin{definition}[$p$-Gruppe]
	Sei $p$ eine Primzahl.
	Eine $p$-Gruppe $G$ ist eine Gruppe, in der die Ordnung jedes Elements eine Potenz von $p$ ist.
\end{definition}

\begin{theorem}[Olson]\label{thm:olson}
	Für eine endliche abelsche $p$-Gruppe $G$ mit Invarianten $p^{e_1},\dots,p^{e_r}$ ist die Davenport-Konstante $D(G)=1+\sum_{i=1}^r(p^{e_i}-1)$. 
\end{theorem}

Mit diesem Ergebnis können wir leicht eine für uns relevante Folgerung beschreiben:

\begin{corollary}\label{cor:olson}
	Seien $d\in\N$ und $p\in\N$ eine Primzahl sowie $f^1,\dots,f^r\in\Z^d$ mit $r\geq 1+dp-d$. Dann existiert eine nicht-leere Menge $I\subseteq\firstNumbers{r}$ mit $\sum_{i\in I}f^i\in p\Z^d$.
\end{corollary}
\begin{proof}
	Für die Invarianten $p^{e_1},\dots,p^{e_d}$ der $p$-Gruppe $\Z^d/p\Z^d$ gilt $p^{e_1}=\dots=p^{e_d}=p$ und mit Theorem~\ref{thm:olson} ist $D(\Z^d/p\Z^d)=1+\sum_{i=1}^d(p-1)=1+dp-d$.
	
	Nach Definition der Davenport-Konstante existiert eine nichtleere Menge $I\subseteq\firstNumbers{1+dp-d}$ mit $\sum_{i\in I}[f^i]_p=[0]_p=p\Z^d$.
	Mit $\firstNumbers{1+dp-d}\subseteq\firstNumbers{r}$ und $\sum_{i\in I}[f^i]_p=[\sum_{i\in I}f^i]_p$ folgt die Behauptung.
\end{proof}

Damit können wir das folgende Lemma zeigen, das wir im nächsten Abschnitt benötigen werden:

\begin{lemma}
	Seien $d,k\in\N, u^1,\dots, u^k\in\Z^d$ und $\alpha_1,\dots,\alpha_k\geq0$ mit $\sum_{i=1}^k \alpha_i\geq d$.
	Für $i=1,\dots,k$ existieren $\beta_i\in[0,\alpha_i]$, wobei nicht alle $\beta_i=0$ und $\sum_{i=1}^k\beta_i u^i \in\Z^d$.
\end{lemma}
\begin{proof}
	\newcommand{\bbeta}{\tilde{\beta}}
	Ohne Beschränkung der Allgemeinheit ist $\alpha_i>0$ für $i=1,\dots,k$, denn für $\alpha_i=0$ wird $\beta_i=0$ vorausgesetzt, wodurch das Resultat nicht verändert werden kann.
	
	Zunächst betrachten wir den Fall der Existenz einer Primzahl $p$, sodass   $\alpha_i=q_i / p$ mit $q_i\in\N$ für $i\in\firstNumbers{k}$.
	Wir können nun Korollar~\ref{cor:olson} auf die Vektoren
	$$\underbrace{u^1,\dots,u^1}_{q_1~\text{Einträge}},~\dots~,\underbrace{u^k,\dots,u^k}_{q_k~\text{Einträge}}$$
	anwenden, da $r:=\sum_{i=1}^k q_i=(\sum_{i=1}^k \alpha_i)\cdot p\geq dp \geq 1+dp-d$ nach Annahme.
	Dadurch erhalten wir $l_i\in\{0,\dots,q_i\}$ für $i\in\firstNumbers{k}$ mit nicht alle $l_i=0$ und $\sum_{i=1}^k l_i\cdot u^i\in p\Z^d$.
	Teilen wir durch $p$ gelangen wir mit $\beta_i := l_i/p$ zu unserer Behauptung $\sum_{i=1}^k \beta_i\cdot u^i\in\Z^d$ und nicht alle $\beta_i=0$ sowie $\beta_i\in[0,\alpha]$, da $0\leq l_i/p\leq q_i/p=\alpha_i$.
	
	Den allgemeinen Fall führen wir auf den ersten zurück, indem wir $(\alpha_1,\dots,\alpha_k)\in\R^k$ durch Brüche mit Primzahlen im Nenner annähern.
	Dazu definieren wir die Folge 
	$$
	(v_j)_{j\in\N}:=(q_{j,1}/p_j,\dots,q_{j,k}/p_j)_{j\in\N}$$
	mit $q_{j,i}\in\N$, $p_j$ Primzahl und $q_{i,j}/p_j\in[\alpha_i, \alpha_i+j^{-1}]$.
	Damit ist $\lim_{j\rightarrow\infty}v_j=(\alpha_1,\dots,\alpha_k)$ und für $j\in\N$ können wir den ersten Fall auf $u$ und $v_j$ anwenden und erhalten $\beta_{j,1},\dots,\beta_{j,k}$ mit $\beta_{j,i}\in[0,v_{j,i}]$ und nicht alle $\beta_{j,i}=0$ sowie $\sum_{i=1}^k\beta_{j,i}u^i \in\Z^d$.
	Da die Folge $(\beta_{j,1},\dots,\beta_{j,k})_{j\in\N}$ in der kompakten Menge $[0,\alpha_1+1]\times\cdots\times[0,\alpha_k+1]$ liegt, existiert nach Satz von Bolzano-Weierstraß eine konvergente Teilfolge mit $\lim_{j\rightarrow\infty}(\beta_{\sigma(j),1},\dots,\beta_{\sigma(j),k})=:(\beta_1,\dots,\beta_k)$.
	Da $\beta_{\sigma(j),i}\in[0,v_{\sigma(j),i}]$ und $\lim_{j\rightarrow\infty}v_{\sigma(j),i}=\alpha_i$ ist $\beta_i\in[0,\alpha_i]$.
	Da es nur endlich viele $z\in\Z^d$ der Form $z=\sum_{i=1}^k\gamma_i u^i$ mit $\gamma_i\in[0,\alpha_i+1]$ gibt, existiert ein Punkt $z\in\Z^d$ für den $\sum_{i=1}^k \beta_{\sigma(j),i} u^i=z$ für unendlich viele $j$ gilt.
	Also gibt es wegen der Konvergenz von $(\beta_{\sigma(j),i})_{j\in\N}$ ein $n$, sodass $\sum_{i=1}^k\beta_{\sigma(j),i}u^i=z$ für $j\geq n$ und damit $\sum_{i=1}^k\beta_i u^i=z$.
	Sind nicht alle $\beta_i=0$, so erfüllen die $\beta_i$ die Behauptung.
	Andernfalls ist $z=0$. Setze $\varepsilon>0$, sodass $\varepsilon\beta_{n,i}\in[0,\alpha_i]$ für $i\in\firstNumbers{k}$.
	Dann sind nach Wahl der $\beta_{n,i}$ nicht alle der $\varepsilon\beta_{n,i}=0$ und $\sum_{i=1}^k\varepsilon\beta_{n,i}u^i=\varepsilon z=\zero\in\Z^d$.
\end{proof}

\subsection{Abschätzung in Abhängigkeit der Anzahl ganzzahliger Variablen}
Dieser Abschnitt verfolgt das Ziel eine Abschätzung optimaler Lösungen zweier gemischt-ganzzahliger Programme	($I$-\MIP) und ($J$-\MIP) in Abhängigkeit von $\Delta$ und $\betrag{I\cup J}$ zu finden.

Zunächst betrachten wir noch folgendes Hilfslemma über die Darstellung eines Kegels:
\begin{lemma}\label{lem:cone}
	Sei $A\in\Z^{m\times n}$, dessen Zeilen in zwei Untermatrizen $A_1$ und $A_2$ aufgeteilt sind.
	Die Menge $C:=\{ x\in\R^n \mid A_1x\leq 0, A_2x\geq0 \}$ ist ein Kegel und besitzt die Darstellung \[ C=\{\lambda_1 v^1+\dots+\lambda_kv^k \mid \forall i\in\firstNumbers{k} \colon\lambda_i\geq0 \}\] mit $v^i\in\Z^n$ und $\norm{v^i}\leq\Delta$ für $i\in\firstNumbers{k}$.
\end{lemma}
\begin{proof}
	Seien $x\in C$ und $\alpha>0$ gegeben.
	Dann $A_1 \alpha x=\alpha A_1 x\leq 0$ und $A_2\alpha x\geq0$, also $\alpha x\in C$ und damit $C$ ein Kegel.
	
	\todo{Darstellung: \glqq standard arguments involving Cramer's rule\grqq.}
\end{proof}

\todo{Maybe move this to a theorem in 2.1:}
\begin{lemma}\label{lem:maxgamma}
	Seien $u^1,\dots,u^k\in\Z^d$ und $\lambda_1,\dots,\lambda_k\geq0$ gegeben.
	Ist 
	$$G:=\{\gamma \in \bigtimes_{i=1}^k [0,\lambda_i] \mid \sum_{i=1}^k \gamma_i u^i\in\Z^d \},$$
	so existiert ein $\gamma\in G$ mit $\sum_{i=1}^k(\lambda_i-\gamma_i)<d$.
\end{lemma}
\begin{proof}
	$G$ ist beschränkt. Außerdem ist $G$ abgeschlossen: Sei $(\gamma^n)_{n\in\N}$ eine in $\R^k$ konvergente Folge mit $\gamma^n\in G$ für $n\in\N$ und $\lim_{n\to\infty}\gamma^n=:\tilde{\gamma}\in\bigtimes_{i=1}^k [0,\lambda_i]$.
	Da es nur endlich viele $z\in\Z^d$ gibt mit $z=\sum_{i=1}^k\gamma_iv^i$ für $\gamma_i\in[0,\lambda_i]$, existiert ein $z\in\Z^d$, sodass $z=\sum_{i=1}^k\gamma^n_iv^i$ für unendlich viele $\gamma^n$ gilt und damit auch für $\gamma$.
	Also ist $\gamma\in G$ und $G$ abgeschlossen.
	Mit dem Satz von Heine-Borel ist $G\subseteq\R^n$ kompakt.
	Nach dem Satz von Weierstraß nimmt die Menge $\{ \sum_{i=1}^k\gamma_i \mid \gamma\in G \}$ also bei einem $\gamma\in G$ ihr Maximum an.
	
	Wir nehmen nun an $\sum_{i=1}^k(\lambda_i - \gamma_i) \geq d$.
	Wenden wir Lemma~\ref{thm:olson} an auf $\alpha_i=\lambda_i-\gamma_i\geq0$ und $u^i$ für $i\in\firstNumbers{k}$, erhalten wir $\beta_i\in[0,\lambda_i-\gamma_i]$ mit nicht alle $\beta_i=0$ und $\sum_{i=1}^k \beta_i u^i\in\Z^d$.
	Für $\gamma':=\gamma+\beta\leq\lambda$ gilt nun 
	$
	\sum_{i=1}^k\gamma'_iv^i = \sum_{i=1}^k\gamma_iv^i + \sum_{i=1}^k \beta_iv^i\in\Z^d
	$
	und damit ist $\gamma'\in G$.
	Da nicht alle $\beta_i=0$ ist $\sum_{i=1}^k\gamma'_i > \sum_{i=1}^k\gamma_i$, was im Widerspruch zur Maximalität von $\gamma$ steht.
\end{proof}
Nun formulieren wir unser Theorem:

\begin{theorem}
	Seien $I,J\subseteq\firstNumbers{n}$, sodass ($J$-\MIP) eine optimale Lösung $\tilde{y}$ hat.
	Für jede optimale Lösung $x^*$ von ($I$-\MIP) existiert eine optimale Lösung $y^*$ von ($J$-\MIP) mit $\norm{x^*-y^*}\leq\betrag{I\cup J}\cdot\Delta$.
\end{theorem}
\begin{proof}
	Zunächst tauschen wir alle ganzzahligen Variablen an die ersten Stellen und können $\betrag{I\cup J}=\firstNumbers{d}$ mit $d\in\firstNumbers{n}$ annehmen.
	Es sei eine optimale Lösung $x^*$ von ($I$-\MIP) gegeben.
	Setze $z:=\tilde{y}-x^*$ sowie $C:=\{ x\in\R^n \mid A_1 x \leq 0, A_2x\geq0 \}$, wobei die Zeilen von $A$ in $A_1$ und $A_2$ so aufgeteilt werden, dass $A_1y<0$ und $A_2y\geq0$.
	Da $y\in C$, erhalten wir nach Lemma~\ref{lem:cone} die Darstellung 
	$$y = \lambda_1v^1 + \dots+\lambda_kv^k$$
	mit $\lambda_i\geq0$, $\norm{v^i}\leq \Delta$ und $v^i\in C\cap\Z^n$ für $i\in\firstNumbers{k}$.
	Man setze $u^i$ als die Projektion von $v^i$ auf die ersten $d$ Komponenten.
	Nach Lemma~\ref{lem:maxgamma} erhalten wir damit ein $\gamma\in\bigtimes_{i=1}^k[0,\lambda_i]$ mit  $\sum_{i=1}^k\gamma_iu^i\in\Z^d$ und $\sum_{i=1}^k(\lambda_i -\gamma_i)<d$.
	
	Wir definieren nun unseren Kandidaten $$y^*:=\tilde{y}-\sum_{i=1}^k\gamma_iv^i=x^*+\sum_{i=1}^k(\lambda_i-\gamma_i)v^i$$
	sowie $$\tilde{x}:=x^*+\sum_{i=1}^k\gamma_iv^i=\tilde{y}-\sum_{i=1}^k(\lambda_i-\gamma_i)v^i.$$
	Wir zeigen zunächst, dass $y^*$ für ($J$-\MIP) und $\tilde{x}$ für ($I$-\MIP) zulässig sind.
	Dabei sind für $j\in J$ bzw. $i\in I$ die Koordinaten $y^*_j$ bzw. $\tilde{x}_i\in\Z$, da $\tilde{y}_j$ bzw. $x^*_i\in\Z$ und $i,j\in\firstNumbers{d}$ sowie $\sum_{l=1}^k\gamma_lv^l\in\Z^d\times\R^{n-d}$.
	$Ay^*\leq b$ und $A\tilde{x}\leq b$ folgen nun mit $v^i\in C$ für $i\in\firstNumbers{k}$ und 
	$$
	\begin{array}{llll}
	A_1 y^* &=A_1x^*+\sum_{i=1}^k(\lambda_i-\gamma_i)A_1v^i &\leq A_1 x^* &\leq b_1\\
	A_2 y^* &=A_2\tilde{y}-\sum_{i=1}^k\gamma_iA_2v^i &\leq A_2\tilde{y} &\leq b_2\\
	A_1\tilde{x} &=A_1x^*+\sum_{i=1}^k \gamma_iA_1v^i &\leq A_1x^* &\leq b_1\\
	A_2\tilde{x} &=A_2\tilde{y}-\sum_{i=1}^k(\lambda_i-\gamma_i)A_2v^i&\leq A_2\tilde{y}&\leq b_2.
	\end{array}
	$$
	
	Da $x^*$ optimal für ($I$-\MIP), gilt $c\transpose x^*\geq c\transpose \tilde{x} = c\transpose x^* + c\transpose (\sum_{i=1}^k\gamma_iv^i)$ und  $c\transpose(\sum_{i=1}^k\gamma_iv^i)\leq0$.
	Damit erhalten wir mit der Optimalität von $\tilde{y}$ für ($J$-\MIP) und
	$$c\transpose y^*=c\transpose\tilde{y}-c\transpose(\sum_{i=1}^k\gamma_iv^i)\geq c\transpose\tilde{y}$$
	auch die Optimalität von $y^*$ für ($J$-\MIP).
	Außerdem gelten die folgenden Abschätzungen:
	$$\norm{x^*-y^*}=\norm{\sum_{i=1}^k(\lambda_i-\gamma_i)v^i}\leq \sum_{i=1}^k(\lambda_i-\gamma_i)\norm{v^i}\leq \sum_{i=1}^k(\lambda_i-\gamma_i)\Delta< d\cdot\Delta.
	$$
\end{proof}
